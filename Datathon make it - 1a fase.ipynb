{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "URSZHlDOL8cm",
   "metadata": {
    "id": "URSZHlDOL8cm"
   },
   "source": [
    "In the scope of the first assignment of the Quantitative Case Study course, a classification problem was presented in the form of a  Kaggle competition.<br>\n",
    "The problem involves the published data containing information on a range of products from different establishments. The purpose of this work is to use the provided data to create a model, which is able to correctly classify if a product is being sold with a discount or not.<br>\n",
    "Before starting, it should be said, that usually there is only one explanation per subsection. This explanation can be at the start or at the end in a separte subsection of that group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b64e5",
   "metadata": {
    "id": "0b6b64e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")                     \n",
    "%matplotlib inline\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff8d73",
   "metadata": {
    "id": "9dff8d73"
   },
   "source": [
    "The first step of development of this project was to import the necessary basic libraries other functions to enabled an easier analysis of the data, such as: \n",
    "* filtering all the warning that were not necessary\n",
    "* automatically ploting the graphs\n",
    "* set a basic style for seaborn that can be overwritten later\n",
    "* force jupyter to show all the columns from any data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6251c621",
   "metadata": {
    "id": "6251c621"
   },
   "outputs": [],
   "source": [
    "target=pd.read_csv('travel_test.csv') #change file\n",
    "df=pd.read_csv('travel_train.csv') #change file\n",
    "numbers=['MONTANTE']\n",
    "integers=[]\n",
    "continuous=['MONTANTE']\n",
    "categorical=['CATEGORIA','DESCRICAO CATEGORIA', 'DATA']\n",
    "X=categorical+numbers\n",
    "Y = 'target'\n",
    "#df.loc[:,Y]=df.loc[:,Y].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6020d5d",
   "metadata": {
    "id": "e6020d5d"
   },
   "source": [
    "Secondly, both the trainning and test data sets were loaded and their attributes separated according to their variable type. <br>\n",
    "The \"d \" variables classified as categorical variables and the \"x\" variables, classified as numerical, were further separated between discrete (x1, x2, x4, x6, x7 and x8) and continuous (x3, x5 and x9) variables to facilitate the analysis of the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ed1c6b",
   "metadata": {
    "id": "53ed1c6b"
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Zy7MFcJyhotl",
   "metadata": {
    "id": "Zy7MFcJyhotl"
   },
   "source": [
    "Afterwards, a preliminary analysis was conducted starting by analysing the size of the data set, which is composed by 28 variables and 3676 entries. The variables presented are the \"d\" and \"x\" varaibles previously mentioned, the target variable \"y\" and the identificator \"i\". <br>\n",
    "The imbalance of the data set was verified by the frequencies of the target variable, which is composed by 2920 \"0\" and 756 \"1\". <br>\n",
    " Finalizing this overview it is possible to infere from the tables describing the numeric and categorical atributes that the variable \"x9\" has missing values by having a lower count than the remaining numeric variables and all the categorical variables are binary with very high frequency for their mode \"0\" compared to the value \"1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1397c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8f1397c4",
    "outputId": "6c9eb114-3c12-4bd3-daa0-5918c9fccccd"
   },
   "outputs": [],
   "source": [
    "#top of the data (first lines)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f89056",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5f89056",
    "outputId": "d73f37a6-fa3e-4e9d-b942-2d955286b2bd"
   },
   "outputs": [],
   "source": [
    "#size of the data frame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac698a9",
   "metadata": {
    "id": "8ac698a9",
    "outputId": "e5d0210b-34ef-4289-defd-7607359bd954"
   },
   "outputs": [],
   "source": [
    "df[Y].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e201a6",
   "metadata": {
    "id": "35e201a6",
    "outputId": "96bdaa3b-d45e-49a6-f56c-7bae90d18a65"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46020f5",
   "metadata": {
    "id": "e46020f5",
    "outputId": "a9326f95-6522-4f0c-dc67-f512fc9b8c60"
   },
   "outputs": [],
   "source": [
    "df[numbers].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66baaf1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "f66baaf1",
    "outputId": "8242226d-5de9-4b46-a7bb-03dca061df34",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# alterar vari√°veis\n",
    "tmp=df.copy(deep=False)\n",
    "tmp=tmp.loc[:,[Y]+categorical].astype('category')\n",
    "tmp.describe(include='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Feature engeneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"DATA\"] = pd.to_datetime(df[\"DATA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Month'] = df['DATA'].dt.strftime('%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit_transform(df['CATEGORIA'].astype(str) +\"-\"+ df[\"Month\"].astype(str))\n",
    "new_df=pd.DataFrame(lb.fit_transform(df['CATEGORIA'].astype(str) +\"-\"+ df[\"Month\"].astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1=pd.concat([df.loc[:,['ID','MONTANTE']], new_df], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(2,110):\n",
    "    df1.iloc[:,i]=df1.iloc[:,i]*df1.iloc[:,1]\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1=df1.rename(columns={0: \"ID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_df=df1.groupby(by='ID').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(2,110):\n",
    "    last_df = last_df.rename({i: list(lb.classes_)[i-2]}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_df = last_df.rename({1: 'Montante'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_df=df.groupby(by='ID')['target'].sum()\n",
    "target_df=pd.DataFrame(target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_df['target'].where(target_df['target'] == 0, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2=pd.concat([last_df, target_df], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,109):\n",
    "    df2 = df2.rename({i: list(lb.classes_)[i-1]}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df2.rename({0: 'Montante'}, axis='columns')\n",
    "df2 = df2.rename({109: 'target'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2[\"PesoLazerViagem\"] = ((df2[\"17-01\"] + df2[\"17-02\"] + df2[\"17-03\"] + df2[\"17-04\"])/(df2[\"21-01\"] + df2[\"21-02\"] + df2[\"21-03\"] + df2[\"21-04\"] + df2[\"22-01\"] + df2[\"22-02\"] + df2[\"22-03\"] + df2[\"22-04\"])).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8119bbb",
   "metadata": {
    "id": "e8119bbb"
   },
   "source": [
    "# Graphic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MZz9stcn3n_N",
   "metadata": {
    "id": "MZz9stcn3n_N"
   },
   "source": [
    "In the variable x3, most values fall between 0 and 1, having the majority of the observations lying between 0 and 0.5, with peak in the range of 0.25-0.5. Also, there are some observations that are potential outliers, which can be spotted by looking at the bars of the ranges [1.75, 2[ and [2.75, 3[.\n",
    "\n",
    "With regards to x5, the distribution of this variable is skewed to the right. Most of the observations lie below the value 3.1. The tail of this distribution have more observations than the right tail of x3, which will result in a boxplot with more observations that lie beyond the upper fence than the boxplot of the variable x3.\n",
    "\n",
    "Finally, x9 has 3 bins that can be seen as local peaks. The interval of these bins are [1.00, 3.65[, [16.90, 19.55[ and [40.75, 4.40[. The histogram of this variable contrasts with the histograms of x3 and x5, that clearly have right tails with progressively less observations as the value on the x-axis increases. In this variable, there are many observations from the minimum to the maximum value observed in it, which could mean that this variable has no outliers (to be confirmed looking at the boxplot of this variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FR7uXlzALte7",
   "metadata": {
    "id": "FR7uXlzALte7"
   },
   "source": [
    "The observations of the variable x1 are balanced, having close numbers of observations with each of the 7 existing values, unlike the other variables in these plots. X4 has the vast majority of the observations in one value only (out of 3) and x2 is unbalanced, having an uneven distribution of observations among the 4 different observed values. The variables x6, x7 and x8 are extremely unbalanced, with many observations concentrated in only a few number of observed values, and a very small number of observations in many observed values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M1bACuXNOor9",
   "metadata": {
    "id": "M1bACuXNOor9"
   },
   "source": [
    "The boxplots of the variables x1, x2 and x9, it can be seen that there are no outliers and the distance of the 1st quartile and the 3rd quartile to the median is similar in each of these variables, which hints that it's very likely that the median and the mean of these variables are close (in relative terms), i.e., the distribution skewness of these variables may be be very low.\n",
    "\n",
    "Looking at the boxplots of the variables x3, x5, x7 and x8 show many outliers and that the distance of the median to the 1st and to the 3rd quartile aren't similar, which means that the distributions of these variables are skewed. Apart from x7, the other 3 variables have many outliers.\n",
    "\n",
    "The boxplot of the variable x4 shows that the median, 1st and 3rd quartile are equal. Since this variable is discrete, it means that there are only 3 different values observed in this variable (1, 2 and 3) and that at least 75% of the observations are equal to 1, which makes all the observations equal to 2 and 3 outliers.\n",
    "\n",
    "With regards to the variable x6, the only meaningful information that can be drawn is that it has no outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7rl1EV4VRvux",
   "metadata": {
    "id": "7rl1EV4VRvux"
   },
   "source": [
    "All the categorical variables are extremely unbalanced. Each of them have only 2 categories, and the vast majority of the observations fall into only one category of each variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DWZyaYQRSPe6",
   "metadata": {
    "id": "DWZyaYQRSPe6"
   },
   "source": [
    "The conclusion drawn from the pie chars is the same as the one drawn from the barplots, with the additional information that at least 83% of the observations fall into only one category of each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rrpvKkAiS1YQ",
   "metadata": {
    "id": "rrpvKkAiS1YQ"
   },
   "source": [
    "With regards to the numerical variables, only 5 variables have outliers (x3, x4, x5, x7 and x8). All the outliers observed are upper outliers. Also, the variables x3 and x5 many outliers, whereas x4, x7 and x8 have much less."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RZnwDcfxUVpp",
   "metadata": {
    "id": "RZnwDcfxUVpp"
   },
   "source": [
    "It is possible to confirm that among all variables, only x9 has missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AhgEkYoLUndn",
   "metadata": {
    "id": "AhgEkYoLUndn"
   },
   "source": [
    "It was also verified that there are no duplicate rows in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0fc777",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fa0fc777",
    "outputId": "8d75138f-8174-45d3-da82-c4b0f5b49afa"
   },
   "outputs": [],
   "source": [
    "# histograms\n",
    "\n",
    "for i in continuous:\n",
    "    fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "    #plots histogram, returns counts, bin border values, and the bars themselves\n",
    "    h_vals, h_bins, h_bars = ax.hist(df[f'{i}'], bins=100, edgecolor=\"white\")\n",
    "    #plot x ticks at the place where the bin borders are\n",
    "    ax.set_xticks(np.round_(h_bins, decimals=2))\n",
    "    ax.set_title(f'{i}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44563b79",
   "metadata": {
    "id": "44563b79",
    "outputId": "32e013b8-1b26-49a2-ba09-d74f2760bd20"
   },
   "outputs": [],
   "source": [
    "# barplots for discrete variables\n",
    "\n",
    "for i in integers:\n",
    "    fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "    sns.countplot(y = df[i][1:],data=df, order=df[i][1:].value_counts().index, palette='Blues_r')\n",
    "    fig.text(0.1, 0.95, f'{i}', fontsize=16, fontweight='bold', fontfamily='serif')\n",
    "    plt.xlabel(' ', fontsize=20)\n",
    "    plt.ylabel('')\n",
    "    plt.yticks(fontsize=13)\n",
    "    plt.box(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2702427",
   "metadata": {
    "id": "b2702427",
    "outputId": "46c3f623-9e9a-4eb5-dbf2-2eac23a702ce",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# boxplots\n",
    "\n",
    "for i in numbers:\n",
    "    fig, ax = plt.subplots(1,1, figsize=(5, 6))\n",
    "    sns.boxplot(y=df[i])\n",
    "    fig.text(0.1, 0.95, f'{i}', fontsize=16, fontweight='bold', fontfamily='serif')\n",
    "    plt.ylabel('')\n",
    "    frame1 = plt.gca()\n",
    "    frame1.axes.get_xaxis().set_visible(False)\n",
    "    frame1.axes.get_yaxis().set_visible(False)\n",
    "    plt.yticks(fontsize=13)\n",
    "    plt.box(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6709efec",
   "metadata": {
    "id": "6709efec",
    "outputId": "6a4a53be-a823-4078-f4f6-b377db3b19ab"
   },
   "outputs": [],
   "source": [
    "# barplots for categorical variables\n",
    "\n",
    "for i in categorical:\n",
    "    fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "    sns.countplot(y = df[i][1:],data=df, order=df[i][1:].value_counts().index, palette='Blues_r')\n",
    "    fig.text(0.1, 0.95, f'{i}', fontsize=16, fontweight='bold', fontfamily='serif')\n",
    "    plt.xlabel(' ', fontsize=20)\n",
    "    plt.ylabel('')\n",
    "    plt.yticks(fontsize=13)\n",
    "    plt.box(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f0724",
   "metadata": {
    "id": "6b3f0724",
    "outputId": "f01c22c5-79e5-4891-80fd-ef4b9bb6f297"
   },
   "outputs": [],
   "source": [
    "#Pie chart\n",
    "\n",
    "for i in categorical:\n",
    "    fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "    plt.pie(df[i].value_counts(), labels=df[i].unique(), autopct='%.0f%%')\n",
    "    fig.text(0.1, 0.95, f'{i}', fontsize=16, fontweight='bold', fontfamily='serif')\n",
    "    plt.xlabel(' ', fontsize=20)\n",
    "    plt.ylabel('')\n",
    "    plt.yticks(fontsize=13)\n",
    "    plt.box(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936e5fe8",
   "metadata": {
    "id": "936e5fe8"
   },
   "source": [
    "Number of outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afb263f",
   "metadata": {
    "id": "5afb263f",
    "outputId": "f830d1a3-23dc-4cc5-b874-e36e00890e7f"
   },
   "outputs": [],
   "source": [
    "# check outliers\n",
    "for i in numbers:\n",
    "    var_q1 = df[i].quantile(0.25)\n",
    "    var_q3 = df[i].quantile(0.75)\n",
    "    outlier_top_lim = var_q3 + 1.5 * (var_q3 - var_q1)\n",
    "    outlier_bottom_lim = var_q1 - 1.5 * (var_q3 - var_q1)\n",
    "    print(i)\n",
    "    print(\"Upper outliers: {}\".format(df.loc[df[i] > outlier_top_lim, i].count()))\n",
    "    print(\"Lower outliers: {}\".format(df.loc[df[i] < outlier_bottom_lim, i].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XILwSZsb2UZh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XILwSZsb2UZh",
    "outputId": "166a3d7b-5567-47bb-84e8-1f09059dff38"
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "for i in numbers:\n",
    "    z_score_upper_outlier = df[stats.zscore(df[i]) > 3]\n",
    "    z_score_lower_outlier = df[stats.zscore(df[i]) < -3]\n",
    "    print(i)\n",
    "    print(\"Upper outliers: {}\".format(z_score_upper_outlier[i].count()))\n",
    "    print(\"Lower outliers: {}\".format(z_score_lower_outlier[i].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72e749",
   "metadata": {
    "id": "7f72e749",
    "outputId": "bf807c79-80ff-49eb-87ae-158e4b014631"
   },
   "outputs": [],
   "source": [
    "#check missing values\n",
    "\n",
    "missing = []\n",
    "for coln in df.columns:\n",
    "    if df[coln].isnull().values.any():\n",
    "        missing.append(coln)\n",
    "\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05609f12",
   "metadata": {
    "id": "05609f12",
    "outputId": "4a49fdb0-658b-4d53-948d-b2216e72261c"
   },
   "outputs": [],
   "source": [
    "# number of missing values\n",
    "for i in missing:\n",
    "    print(i + ': '+ str(df[i].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eff371",
   "metadata": {
    "id": "82eff371",
    "outputId": "766b32a5-f4f5-45f8-b5c7-2baa55aab791"
   },
   "outputs": [],
   "source": [
    "# duplicate rows\n",
    "\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b8cfb0",
   "metadata": {
    "id": "53b8cfb0"
   },
   "source": [
    "# Multivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hJ5DjlGumtZH",
   "metadata": {
    "id": "hJ5DjlGumtZH"
   },
   "source": [
    "To perform a multivariate analysis we started by comparing the values of the variables for the different values of the target variable, obtaining the pair plot. <br>\n",
    "In the pair plot it is possible to analyse the distribution of a single numeric variable throught the density plots, as well as the relationship between two variables in the scatterplots. In this graphics, the orange represents y=1 and the blue y=0. In the scatter plots the y=0 and y=1 are not easily separated and in the density plots it is possible to, once again, verify the imbalance of the data, aswell as verify that the distributions for y=0 and y=1 are similar.The similarity in the distributions can also be seen in the boxplots of the numeric variables and the imbalance of the data set can be easily identified on the bar plots of the categoric variables. The boxplots are also able to represent the outliers found in the variables, which are evaluated and treated in the following chapters. <br>\n",
    "Afterwards, a correlation analysis between the variables was performed. The only notable correlations found were between x4 and d1 with 0.74 and d10 and d13 with 0.62. This is information is valuable to perform feature selection, but as it will be presented in the Feature Selection chapter of the project, the feature selection process was automated. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8877dda",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a8877dda",
    "outputId": "72edbd7e-6b78-484d-9df5-20fe32977f94"
   },
   "outputs": [],
   "source": [
    "# matrix graph\n",
    "\n",
    "sns.pairplot(df[[Y]+numbers], hue=Y, size=3, diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d7420",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "id": "549d7420",
    "outputId": "aa8d968f-5ae5-4e3f-f292-eecde272e334"
   },
   "outputs": [],
   "source": [
    "# correlation heatmap (only number variables)\n",
    "\n",
    "corr = df[numbers].corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "ax = sns.heatmap(corr, cmap=\"Blues\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UxqZY553akjU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UxqZY553akjU",
    "outputId": "78226321-a9f4-4f42-913f-23b42968d6ac"
   },
   "outputs": [],
   "source": [
    "# correlation heatmap \n",
    "\n",
    "corr = df[[Y]+X].corr(method='spearman')\n",
    "f, ax = plt.subplots(figsize=(24, 18))\n",
    "ax = sns.heatmap(corr, cmap=\"Blues\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a15efd",
   "metadata": {
    "id": "04a15efd",
    "outputId": "f26b7e1e-c105-411e-a432-4834fde7e42b"
   },
   "outputs": [],
   "source": [
    "# barplots for categorical variables\n",
    "\n",
    "for i in categorical:\n",
    "    fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "    sns.countplot(y = df[i][1:], hue=Y, data=df, order=df[i][1:].value_counts().index, palette='Blues_r')\n",
    "    fig.text(0.1, 0.95, f'{i}', fontsize=16, fontweight='bold', fontfamily='serif')\n",
    "    plt.xlabel(' ', fontsize=20)\n",
    "    plt.ylabel('')\n",
    "    plt.yticks(fontsize=13)\n",
    "    plt.box(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#boxplots\n",
    "\n",
    "df[[Y]+numbers].boxplot(by=Y, figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1a70712",
   "metadata": {
    "id": "c1a70712"
   },
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dcd9f0",
   "metadata": {
    "id": "82dcd9f0"
   },
   "source": [
    "Due to the limitations of certain models, it is sometimes necessary to substitute the missing values. There are some exceptions, that is, models that have an internal mechanism that can handle missing values. So, since we want to try different models, different methods were used to replace the missing values, in order to test which method is the best in our specific case.<br>\n",
    "\n",
    "Firstly, confirmation of the exitence of missing values in the x9 variable was obtained. Afterwards, to make the df_predict_na a basic optuna automl model was used to find the best parameters of a catboostregressor, to predict the missing values of the x9 variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f79e5",
   "metadata": {
    "id": "660f79e5"
   },
   "outputs": [],
   "source": [
    "def df_mean(df):\n",
    "    for i in missing:\n",
    "        df[i]=df[i].fillna(df[i].mean())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0becdf",
   "metadata": {
    "id": "9b0becdf"
   },
   "outputs": [],
   "source": [
    "def df_median(df):\n",
    "    for i in missing:\n",
    "        df[i]=df[i].fillna(df[i].median())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be31a994",
   "metadata": {
    "id": "be31a994"
   },
   "outputs": [],
   "source": [
    "def df_value(df):\n",
    "    for i in missing:\n",
    "        df[i]=df[i].fillna(9999)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d143d1b",
   "metadata": {
    "id": "9d143d1b"
   },
   "outputs": [],
   "source": [
    "def df_remove_row(df):\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa48bf",
   "metadata": {
    "id": "bafa48bf"
   },
   "outputs": [],
   "source": [
    "def df_remove_col(df):\n",
    "    df = df.dropna(axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1012d60",
   "metadata": {
    "id": "f1012d60"
   },
   "outputs": [],
   "source": [
    "def df_ffill(df):\n",
    "    for i in missing:\n",
    "        df[i] = df[i].fillna(method='ffill')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8819e186",
   "metadata": {
    "id": "8819e186"
   },
   "outputs": [],
   "source": [
    "def df_bfill(df):\n",
    "    for i in missing:\n",
    "        df[i] = df[i].fillna(method='bfill')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tX0FrYLs8sas",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "id": "tX0FrYLs8sas",
    "outputId": "30b5b929-f696-4370-a7cb-8e5f1abe3c0e"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "import optuna\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # Definition of space search\n",
    "    depth = trial.suggest_int('depth', 3, 16)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0, 1, step=0.05)\n",
    "    iterations = trial.suggest_int('iterations', 2, 2000)\n",
    "\n",
    "    # Classifier definition\n",
    "    model = CatBoostRegressor(depth=depth,\n",
    "                                learning_rate=learning_rate,\n",
    "                                iterations=iterations,logging_level='Silent')\n",
    "    y_pred=model.fit(df[X].fillna(df['x9'].mean()),df[Y]).predict(df[X].fillna(df['x9'].mean()))\n",
    "\n",
    "    return r2_score(df[Y],y_pred)\n",
    "\n",
    "study=optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd36a7",
   "metadata": {
    "id": "fbbd36a7"
   },
   "outputs": [],
   "source": [
    "def df_predict_na(df):\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    from sklearn.linear_model import SGDRegressor\n",
    "    from catboost import CatBoostRegressor\n",
    "    from sklearn.kernel_ridge import KernelRidge\n",
    "    from xgboost.sklearn import XGBRegressor\n",
    "    from lightgbm import LGBMRegressor\n",
    "    from  sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df_replica=df.dropna().copy(deep=False)\n",
    "    df_replica.index=list(range(len(df_replica)))\n",
    "\n",
    "    standardized_df = pd.DataFrame(scaler.fit_transform(df_replica.loc[:,'x1':'x8']))\n",
    "\n",
    "    mydf=df_replica.loc[:,categorical]\n",
    "\n",
    "    for coln in standardized_df.columns:\n",
    "        mydf[coln]=standardized_df[coln]\n",
    "\n",
    "    y_train = df[\"x9\"].dropna()\n",
    "    \n",
    "    X_train = mydf\n",
    "    X_train.rename(columns={0:'x1',1:'x2',2:'x3', 3:'x4',4:'x5',5:'x6',6:'x7',7:'x8'},inplace=True)\n",
    "    X_test = df.loc[:,'d1':'x8']\n",
    "    \n",
    "    model = CatBoostRegressor(depth= 5, learning_rate= 0.55, iterations= 636,logging_level='Silent')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(r2_score(y_train,model.predict(X_train)))\n",
    "    print(plt.scatter(y=y_pred,x=range(len(np.array(y_pred)))))\n",
    "\n",
    "    for i in range(0,len(df['x9'])):\n",
    "\n",
    "        if pd.isnull(df.iloc[i,len(df.columns)-1]):\n",
    "            df.iloc[i,len(df.columns)-1]=pd.DataFrame(y_pred).iloc[i,0]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934feacd",
   "metadata": {
    "id": "934feacd"
   },
   "outputs": [],
   "source": [
    "def df_knn(df):\n",
    "    \n",
    "    from sklearn.impute import KNNImputer\n",
    "\n",
    "    imp = KNNImputer(n_neighbors=2, weights='uniform')\n",
    "    idf=pd.DataFrame(imp.fit_transform(df[X]))\n",
    "    idf.columns=df[X].columns\n",
    "    idf.index=df[X].index\n",
    "    train=idf\n",
    "\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39beec75",
   "metadata": {
    "id": "39beec75"
   },
   "source": [
    "# Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd886792",
   "metadata": {
    "id": "fd886792"
   },
   "source": [
    "Since this data set is very unbalanced, being the majority of y equal to 1, another step that could be used in the pre-processing phase is the the data set balancing. For this, we used two of the most common oversampling and undersampling methods used for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8a3764",
   "metadata": {
    "id": "6b8a3764"
   },
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "def oversampling_random(df):\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    over_sampler = RandomOverSampler(random_state=42)\n",
    "    X_res, y_res = over_sampler.fit_resample(df[X], df[Y])\n",
    "\n",
    "    return pd.concat([y_res, X_res], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b6d5d3",
   "metadata": {
    "id": "77b6d5d3"
   },
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "def oversampling_SMOTE(df):\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "\n",
    "    over_sampler = SMOTE(k_neighbors=2)\n",
    "    X_res, y_res = over_sampler.fit_resample(df[X], df[Y])\n",
    "\n",
    "    return pd.concat([y_res, X_res], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594855ba",
   "metadata": {
    "id": "594855ba"
   },
   "outputs": [],
   "source": [
    "#Undersampling\n",
    "def undersampling_nearmiss(df):\n",
    "    from imblearn.under_sampling import NearMiss\n",
    "    \n",
    "    under_sampler = NearMiss()\n",
    "    X_res, y_res = under_sampler.fit_resample(df[X], df[Y])\n",
    "    \n",
    "    return pd.concat([y_res, X_res], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61a53f7",
   "metadata": {
    "id": "a61a53f7"
   },
   "outputs": [],
   "source": [
    "#Undersampling\n",
    "def undersampling_random(df):\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    under_sampler = RandomUnderSampler(random_state=42)\n",
    "    X_res, y_res = under_sampler.fit_resample(df[X], df[Y])\n",
    "    return pd.concat([y_res, X_res], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ejp5NQ599tNf",
   "metadata": {
    "id": "ejp5NQ599tNf"
   },
   "source": [
    "# Scaling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35Yvu_TkB_hI",
   "metadata": {
    "id": "35Yvu_TkB_hI"
   },
   "source": [
    "Although this step of the model was not real necessary for our final model, some of the models tested used this step to improve their results, even though, none of them is represented here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cte2qFoL9sqM",
   "metadata": {
    "id": "cte2qFoL9sqM"
   },
   "outputs": [],
   "source": [
    "def df_minmax(df):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    idf=pd.DataFrame(scaler.fit_transform(df.loc[:,numbers]))\n",
    "    idf.columns=df.loc[:,numbers].columns\n",
    "    idf.index=df.loc[:,numbers].index\n",
    "    return pd.concat([df[categorical],idf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5_vBEtQNo1nl",
   "metadata": {
    "id": "5_vBEtQNo1nl"
   },
   "outputs": [],
   "source": [
    "def df_standard(df):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    idf=pd.DataFrame(scaler.fit_transform(df.loc[:,numbers]))\n",
    "    idf.columns=df.loc[:,numbers].columns\n",
    "    idf.index=df.loc[:,numbers].index\n",
    "    return pd.concat([df[categorical],idf], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb295e3",
   "metadata": {
    "id": "afb295e3"
   },
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7a5cdf",
   "metadata": {
    "id": "0d7a5cdf"
   },
   "source": [
    "As it was seen in the boxplots and in our analysis, there are some outliers in this data set. Sometimes it is not appropriate to keep these observations while training. So, it would be wise to try and do something with them in the pre-processing stage.<br>\n",
    "\n",
    "Sadly, it was not possible to tune the lof and isolation forest, since we do not real know if an observation really is an outliers, thus meaning, we do not have a measure to base on while tunning the model. Therefore, random isolation forests and lofs were used. However, the IQR and z-score do not require tunning, so no random model regarding these were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefccaf3",
   "metadata": {
    "id": "cefccaf3"
   },
   "outputs": [],
   "source": [
    "def find_outliers_iforest(df):    \n",
    "    from sklearn.ensemble import IsolationForest\n",
    "\n",
    "    forest_df=df.loc[:, :]\n",
    "    clf = IsolationForest(random_state=0).fit(df[X]).predict(df[X])\n",
    "    forest_df=forest_df[clf==1]\n",
    "    return forest_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e6e115",
   "metadata": {
    "id": "04e6e115"
   },
   "outputs": [],
   "source": [
    "def find_outliers_IQR(df):\n",
    "    df_IQR=df.loc[:, [Y, *categorical]]\n",
    "    Q1=df[numbers].quantile(0.25)\n",
    "    Q3=df[numbers].quantile(0.75)\n",
    "    outlier_top_lim = Q3 + 1.5 * (Q3 - Q1)\n",
    "    outlier_bottom_lim = Q1 - 1.5 * (Q3 - Q1)\n",
    "    df_IQR[numbers]=df[numbers][~((df[numbers]<(outlier_bottom_lim)) | (df[numbers]>(outlier_top_lim)))]\n",
    "    df_IQR=df_IQR.dropna()\n",
    "    return df_IQR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f5a1d8",
   "metadata": {
    "id": "35f5a1d8"
   },
   "outputs": [],
   "source": [
    "def find_outliers_z(df):\n",
    "    from scipy import stats\n",
    "    \n",
    "    df_zscore=pd.DataFrame()\n",
    "    for i in numbers:\n",
    "        z = np.abs(stats.zscore(df[i]))\n",
    "        idx_outliers = np.where(z>3, True, False)\n",
    "        df_zscore[i]=pd.DataFrame(idx_outliers)\n",
    "    df_zscore_train=df[~df_zscore]\n",
    "    df_zscore_train.loc[:, [Y, *categorical]]=df.loc[:, [Y, *categorical]]\n",
    "    df_zscore_train=df_zscore_train.drop('i', axis=1)\n",
    "    df_zscore_train=df_zscore_train.dropna()\n",
    "    return df_zscore_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e231b",
   "metadata": {
    "id": "509e231b"
   },
   "outputs": [],
   "source": [
    "# Local Outlier Factor (LOF), being -1 outlier\n",
    "def find_outliers_lof(df):\n",
    "    from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "    lof = LocalOutlierFactor(n_neighbors=2, metric='manhattan')\n",
    "    lof_prediction = lof.fit_predict(df)\n",
    "    df_lof=df\n",
    "    df_lof=df[lof_prediction==1]\n",
    "    return df_lof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find out best parameter for DBSCAN\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import silhouette_score\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(final_df) #substitute missing value here\n",
    "\n",
    "# If your data has more than 2 dimensions, choose MinPts = 2*dim, where dim= the dimensions of your data set (Sander et al., 1998)\n",
    "neigh = NearestNeighbors(n_neighbors=52)\n",
    "nbrs = neigh.fit(scaled_features)\n",
    "distances, indices = nbrs.kneighbors(scaled_features)\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "\n",
    "#The optimal value for epsilon will be found at the point of maximum curvature.\n",
    "figure(figsize=(13, 6), dpi=80)\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(range(len(distances)), distances)\n",
    "plt.xticks(range(len(distances)))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"distances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_outliers_dbscan(X, eps_range=np.arange(5.0, 50.0, 0.5), min_samples_range=range(5, 15)):\n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(X)\n",
    "\n",
    "    for eps in eps_range:\n",
    "        for min_samples in min_samples_range:\n",
    "            dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "            dbscan.fit(scaled_features)\n",
    "            labels = dbscan.labels_\n",
    "\n",
    "            # compute silhouette score for the current DBSCAN parameters\n",
    "            if len(np.unique(labels)) > 1:\n",
    "                score = silhouette_score(scaled_features, labels)\n",
    "\n",
    "            # if the current score is better than the previous best score, update the best score and best parameters\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = {'eps': eps, 'min_samples': min_samples}\n",
    "\n",
    "    dbscan = DBSCAN(eps=best_params['eps'], min_samples=best_params['min_samples'])\n",
    "    dbscan.fit(scaled_features)\n",
    "    labels = dbscan.labels_\n",
    "    df_dbscan=df2[labels!=-1]\n",
    "    return df_dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3=find_outliers_dbscan(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626d5e46",
   "metadata": {
    "id": "626d5e46"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393bead4",
   "metadata": {
    "id": "393bead4"
   },
   "source": [
    "Another important step of data mining is feature selection. Here we pick the atributes that are most important to make the predictions, that is, help the model get the highest accuracy possible.<br>\n",
    "\n",
    "For this we used recursive feature selection with cross validation and a voting mechanism that used three feature selection models and then verified which features were in common in the mechanisms to choose the best features. This last mechanism was formed because the feature selection of these three models individualy had poor results. <br>\n",
    "\n",
    "The method that gave the best results was the rfecv. In it, we used a randomforestclassifier, as it normally returned a similar data set when compared with the boosting models, but this one had a slight better performance (less run time) than the others. <br>\n",
    "\n",
    "To make a part of the feature selection (exclude x4), we also made use of the explainability that is explored in the last chapter of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5db420",
   "metadata": {
    "id": "7a5db420"
   },
   "outputs": [],
   "source": [
    "def rfecv_df(df):\n",
    "    from sklearn.feature_selection import RFECV\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    rfecv = RFECV(estimator=RandomForestClassifier(), step=1, cv=10,scoring = 'f1_macro')\n",
    "    rfecv=rfecv.fit(df.loc[:,'Montante':'9-04'], df.loc[:,'target'])\n",
    "    new_df=df.loc[:,'Montante':'9-04':].loc[:,rfecv.support_]\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c41b7",
   "metadata": {
    "id": "eb3c41b7"
   },
   "outputs": [],
   "source": [
    "def voting_df(df, n):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    # ExtraTreesClassifier feature selection\n",
    "    from sklearn.ensemble import ExtraTreesClassifier\n",
    "    model = ExtraTreesClassifier(n_estimators = n)\n",
    "    model.fit(df[X], df[Y])\n",
    "\n",
    "    extra_trees=sorted(list(zip(model.feature_importances_,df[X].columns)), key =lambda a: a[0])[::-1][:n]\n",
    "    x=[i[1] for i in extra_trees]\n",
    "    \n",
    "    # recursive feature selection\n",
    "    from sklearn.feature_selection import RFE\n",
    "    rfe = RFE(RandomForestClassifier(), n_features_to_select = n)\n",
    "    fit = rfe.fit(df[X], df[Y])\n",
    "    recursive_selection=sorted(list(zip(fit.ranking_,df[X].columns)), key =lambda a: a[0])[:n]\n",
    "    y=[i[1] for i in recursive_selection]\n",
    "    \n",
    "    # SelectKBest feature selection\n",
    "    from sklearn.feature_selection import SelectKBest\n",
    "    from sklearn.feature_selection import chi2\n",
    "\n",
    "    test=SelectKBest(score_func=chi2, k=n)\n",
    "    fit = test.fit(df[X], df[Y])\n",
    "    selectk=sorted(list(zip(fit.scores_,df[X].columns)), key= lambda a: a[0])[::-1][:n]\n",
    "    z=[i[1] for i in selectk]\n",
    "    var=[i for i in z if i in x and i in z]\n",
    "    \n",
    "    return df.loc[:,var]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287fab33",
   "metadata": {
    "id": "287fab33"
   },
   "source": [
    "# Prepare data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ecd327",
   "metadata": {
    "id": "15ecd327"
   },
   "source": [
    "In this section, a sort of pipeline was formed. In it we pick which function we want from the ones that we have seen so far and then progressively apply to the previously processed data frame. So, it is possible to experiment and observe the results. The steps done to get the best model in this stage were these (feature selection was performed with the commented line, but it sometimes gives a slightly different result, so we wrote down the necessary data frame). However, after applying the explainability models that are at the end of this notebook, it was noticed that some variables explained very little of the data. So, some attempts were made and the best single prediction made with a model was gotten with the features at the end (d2, d11 and all numerical variables with the exception of x4). The reason to do this is explained in the last part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545680f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "545680f1",
    "outputId": "2b1db8a5-5b57-4352-b8ba-657a36ab01a6"
   },
   "outputs": [],
   "source": [
    "#df=pd.read_csv('training.csv')\n",
    "df_no_na = df2\n",
    "df_no_outliers = df_no_na\n",
    "df_balanced= df_no_outliers\n",
    "df_scaled= df_balanced\n",
    "final_df = rfecv_df(df_scaled)\n",
    "# final_df = df_scaled[['d2','d1f1']+numbers]\n",
    "#final_df=df_scaled\n",
    "#final_df = df_scaled[['d2','d11']+numbers[:3]+numbers[4:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing = []\n",
    "for coln in df.columns:\n",
    "    if df[coln].isnull().values.any():\n",
    "        missing.append(coln)\n",
    "\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for i in [LogisticRegression(), DecisionTreeClassifier(), KNeighborsClassifier(), GaussianNB(), DecisionTreeClassifier(), RandomForestClassifier(), SVC(), MLPClassifier(), GradientBoostingClassifier(), CatBoostClassifier(logging_level='Silent'), XGBClassifier(), LGBMClassifier()]:\n",
    "    print(str(i.__class__.__name__) + ': ' + str(cross_val_score(i, final_df, target_df, cv=10, scoring='f1_macro').mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df, target_df, test_size=0.3, random_state=0)\n",
    "\n",
    "# Plot the ROC curve for each classifier\n",
    "plt.figure(figsize=(8,6))\n",
    "for clf in [LogisticRegression(), DecisionTreeClassifier(), KNeighborsClassifier(), GaussianNB(), DecisionTreeClassifier(), RandomForestClassifier(), SVC(), MLPClassifier(), GradientBoostingClassifier(), CatBoostClassifier(logging_level='Silent'), XGBClassifier(), LGBMClassifier()]:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_test)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='{} (AUC = {:.2f})'.format(clf.__class__.__name__, roc_auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Multiple Classifiers')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a4b61",
   "metadata": {
    "id": "d99a4b61"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d04f977",
   "metadata": {
    "id": "4d04f977"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb37ec",
   "metadata": {
    "id": "f2fb37ec"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomforest = RandomForestClassifier(n_jobs=-1)\n",
    "criterion = ['gini', 'entropy', 'log_loss']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "min_samples_split = [int(x) for x in np.linspace(5, 100, num = 10)]\n",
    "min_samples_leaf = [int(x) for x in np.linspace(5, 100, num = 10)]\n",
    "max_features = ['auto', 'sqrt', 'log2'] #The number of features to consider when looking for the best split:\n",
    "max_leaf_nodes = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "bootstrap = [True, False]\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# max_features\n",
    "hyperparameters = dict(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, max_features=max_features, max_leaf_nodes=max_leaf_nodes, bootstrap=bootstrap)\n",
    "randomizedsearch = RandomizedSearchCV(randomforest, hyperparameters, n_iter=100, cv=10, verbose=0, n_jobs=-1)\n",
    "best_model_randomforest = randomizedsearch.fit(final_df, df_no_outliers[Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b7fe0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a94b7fe0",
    "outputId": "cabbf229-5e33-4f76-b14f-179a8ed9bf01"
   },
   "outputs": [],
   "source": [
    "print(best_model_randomforest.best_params_)\n",
    "print(best_model_randomforest.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7ab47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "87a7ab47",
    "outputId": "37c8b4e9-9c51-4c26-a653-a40b245d517c"
   },
   "outputs": [],
   "source": [
    "# confusion matrix with sample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df, df[Y], test_size=0.33, random_state=1)\n",
    "matrix = confusion_matrix(y_test, best_model_randomforest.predict(X_test))\n",
    "print(best_model_randomforest.score(X_test, y_test))\n",
    "dataframe = pd.DataFrame(matrix, index=[0,1], columns=[0,1])\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e6a9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "b38e6a9f",
    "outputId": "571dd8c7-a852-41ba-d304-c759e29a6cca"
   },
   "outputs": [],
   "source": [
    "# roc curve with sample\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df, df[Y], test_size=0.33, random_state=1)\n",
    "\n",
    "# Get predicted probabilities\n",
    "target_probabilities = best_model_randomforest.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Create true and false positive rates\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, target_probabilities)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1458bb5e",
   "metadata": {
    "id": "1458bb5e"
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a126785",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "8a126785",
    "outputId": "fa29d75f-7294-4c9b-91f7-a24ace0f6368",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xgboosted\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "for _ in range(10):\n",
    "    xgboosted = XGBClassifier()\n",
    "    hyperparameters = {'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7,0.8,0.9,1,1.5,2,2.5,3],\n",
    "                  'max_depth': [4,5,6,7,8,9,10,11,12],\n",
    "                  'n_estimators': [500,700,1000,1200,1400,1500,1700, 1800,2000,3000],\n",
    "                  'min_child_weight': [0.1, 0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "                  'colsample_bytree': [0.8, 0.9, 1.0]}\n",
    "\n",
    "    randomizedsearch = RandomizedSearchCV(xgboosted, hyperparameters, cv=5, verbose=0, n_jobs=-1)\n",
    "    best_model_xgboosted = randomizedsearch.fit(final_df, df_no_outliers[Y])\n",
    "    \n",
    "    print(best_model_xgboosted.best_params_)\n",
    "    print(best_model_xgboosted.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f4f0b0",
   "metadata": {
    "id": "d6f4f0b0"
   },
   "outputs": [],
   "source": [
    "print(best_model_xgboosted.best_params_)\n",
    "print(best_model_xgboosted.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77111a",
   "metadata": {
    "id": "ed77111a"
   },
   "outputs": [],
   "source": [
    "# confusion matrix with sample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df, df[Y], test_size=0.33, random_state=1)\n",
    "matrix = confusion_matrix(y_test, best_model_xgboosted.predict(X_test))\n",
    "print(best_model_xgboosted.score(X_test, y_test))\n",
    "dataframe = pd.DataFrame(matrix, index=[0,1], columns=[0,1])\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9498a5a",
   "metadata": {
    "id": "a9498a5a"
   },
   "outputs": [],
   "source": [
    "# roc curve with sample\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df, df[Y], test_size=0.33, random_state=1)\n",
    "\n",
    "# Get predicted probabilities\n",
    "target_probabilities = best_model_xgboosted.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Create true and false positive rates\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, target_probabilities)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc5983f",
   "metadata": {
    "id": "1fc5983f"
   },
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52504dd",
   "metadata": {
    "id": "d52504dd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catboosted = CatBoostClassifier(logging_level='Silent')\n",
    "params = {'depth':[4,5,6,7,8],\n",
    "          'iterations':[1000,1500,2000],\n",
    "          'learning_rate':[0.18,0.2,0.22], \n",
    "          'l2_leaf_reg':[0.08,0.1, 0.12],\n",
    "          'border_count':[200],\n",
    "          'loss_function': ['CrossEntropy'],\n",
    "          'random_strength': [8,9,10,11,12],\n",
    "          'min_data_in_leaf': [25,27,30, 32,35],\n",
    "          'best_model_min_trees': [3,4,5]}\n",
    "\n",
    "randomizedsearch = RandomizedSearchCV(catboosted, params, scoring='f1', cv=10, error_score='raise' )\n",
    "best_model_catboost = randomizedsearch.fit(final_df, df_no_outliers[Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0954cf5",
   "metadata": {
    "id": "e0954cf5"
   },
   "outputs": [],
   "source": [
    "print(best_model_catboost.best_params_)\n",
    "print(best_model_catboost.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbc39cf",
   "metadata": {
    "id": "5cbc39cf"
   },
   "outputs": [],
   "source": [
    "# confusion matrix with sample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df, df[Y], test_size=0.33, random_state=1)\n",
    "matrix = confusion_matrix(y_test, best_model_catboost.predict(X_test))\n",
    "print(best_model_catboost.score(X_test, y_test))\n",
    "dataframe = pd.DataFrame(matrix, index=[0,1], columns=[0,1])\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3502b288",
   "metadata": {
    "id": "3502b288"
   },
   "outputs": [],
   "source": [
    "# roc curve with sample\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df, df[Y], test_size=0.33, random_state=1)\n",
    "\n",
    "# Get predicted probabilities\n",
    "target_probabilities = best_model_catboost.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Create true and false positive rates\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, target_probabilities)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af0416",
   "metadata": {
    "id": "21af0416"
   },
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724ebb5",
   "metadata": {
    "id": "0724ebb5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "decisiontree = DecisionTreeClassifier()\n",
    "svc = SVC(random_state=0)\n",
    "logistic = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "naive_bayes = GaussianNB()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "adaboost = AdaBoostClassifier(random_state=0)\n",
    "base_estimator = [decisiontree, randomforest, svc, knn, logistic, naive_bayes]\n",
    "n_estimators = [10, 20, 50, 100, 150, 200]\n",
    "learning_rate = [0.1, 0.5, 1, 1.5, 2, 3, 4, 5, 10]\n",
    "algorithm = ['SAMME', 'SAMME.R']\n",
    "\n",
    "hyperparameters = dict(base_estimator=base_estimator, n_estimators=n_estimators, learning_rate=learning_rate, algorithm=algorithm)\n",
    "randomizedsearch = RandomizedSearchCV(adaboost, hyperparameters, n_iter=100, cv=10, verbose=0, n_jobs=-1, scoring='f1')\n",
    "best_model_ada = randomizedsearch.fit(final_df, df_no_outliers[Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500e7de",
   "metadata": {
    "id": "b500e7de"
   },
   "outputs": [],
   "source": [
    "print(best_model_ada.best_params_)\n",
    "print(best_model_ada.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de38525f",
   "metadata": {
    "id": "de38525f"
   },
   "outputs": [],
   "source": [
    "# confusion matrix with sample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df, df[Y], test_size=0.33, random_state=1)\n",
    "matrix = confusion_matrix(y_test, best_model_ada.predict(X_test))\n",
    "print(best_model_ada.score(X_test, y_test))\n",
    "dataframe = pd.DataFrame(matrix, index=[0,1], columns=[0,1])\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84152d",
   "metadata": {
    "id": "9d84152d"
   },
   "outputs": [],
   "source": [
    "# roc curve with sample\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df, df[Y], test_size=0.33, random_state=1)\n",
    "\n",
    "# Get predicted probabilities\n",
    "target_probabilities = best_model_ada.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Create true and false positive rates\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, target_probabilities)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aa9d19",
   "metadata": {
    "id": "81aa9d19"
   },
   "source": [
    "## Gradient Boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f06385",
   "metadata": {
    "id": "b1f06385"
   },
   "outputs": [],
   "source": [
    "# Gradient Boosted\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "boosted_tree=GradientBoostingClassifier()\n",
    "hyperparameters = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.05, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.05, 0.5, 12),\n",
    "    \"max_depth\":[2,3,4,5,6,7,8,9],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[10, 30, 50, 70, 100, 150,200, 300, 400, 500]\n",
    "    }\n",
    "\n",
    "randomizedsearch = RandomizedSearchCV(boosted_tree, hyperparameters, n_iter=100, cv=10, verbose=0, n_jobs=-1, scoring='f1')\n",
    "best_model_gradient = randomizedsearch.fit(final_df, df_no_outliers[Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb9e0e",
   "metadata": {
    "id": "f1bb9e0e"
   },
   "outputs": [],
   "source": [
    "print(best_model_gradient.best_params_)\n",
    "print(best_model_gradient.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e137709",
   "metadata": {
    "id": "7e137709"
   },
   "outputs": [],
   "source": [
    "# confusion matrix with sample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df, df[Y], test_size=0.33, random_state=1)\n",
    "matrix = confusion_matrix(y_test, best_model_gradient.predict(X_test))\n",
    "print(best_model_gradient.score(X_test, y_test))\n",
    "dataframe = pd.DataFrame(matrix, index=[0,1], columns=[0,1])\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a164ccb",
   "metadata": {
    "id": "8a164ccb"
   },
   "outputs": [],
   "source": [
    "# roc curve with data\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get predicted probabilities\n",
    "target_probabilities = best_model_gradient.predict_proba(final_df)[:,1]\n",
    "\n",
    "# Create true and false positive rates\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(df[Y], target_probabilities)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a6acc5",
   "metadata": {
    "id": "13a6acc5"
   },
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f140e234",
   "metadata": {
    "id": "f140e234"
   },
   "outputs": [],
   "source": [
    "# LGBM\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "LGBM = LGBMClassifier()\n",
    "gridParams = {\n",
    "    'learning_rate': np.logspace(0,-9, num=30),\n",
    "    'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n",
    "    'num_leaves': [int(x) for x in np.linspace(10, 110, num = 11)], # large num_leaves helps improve accuracy but might lead to over-fitting\n",
    "    'boosting_type' : ['gbdt', 'dart','goss', 'rf'], # for better accuracy -> try dart\n",
    "    'objective' : ['binary'],\n",
    "    'subsample' : np.logspace(0,-9, num=30),\n",
    "    'reg_alpha' : [0.3,0.6,0.9,1,1.2, 1.5, 1.7, 2],\n",
    "    'reg_lambda' : [0.3,0.6,0.9,1,1.2, 1.5, 1.7, 2],\n",
    "    'max_depth' : [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    }\n",
    "\n",
    "randomizedsearch = RandomizedSearchCV(LGBM, gridParams, cv=10, n_jobs=-1, scoring='f1')\n",
    "best_model_lgbm = randomizedsearch.fit(final_df, df_no_outliers[Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc81cafe",
   "metadata": {
    "id": "dc81cafe"
   },
   "outputs": [],
   "source": [
    "print(best_model_lgbm.best_params_)\n",
    "print(best_model_lgbm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf609536",
   "metadata": {
    "id": "bf609536"
   },
   "outputs": [],
   "source": [
    "# confusion matrix with sample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df, df[Y], test_size=0.33, random_state=1)\n",
    "matrix = confusion_matrix(y_test, best_model_lgbm.predict(X_test))\n",
    "print(best_model_lgbm.score(X_test, y_test))\n",
    "dataframe = pd.DataFrame(matrix, index=[0,1], columns=[0,1])\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f06f6b3",
   "metadata": {
    "id": "2f06f6b3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# roc curve with data\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get predicted probabilities\n",
    "target_probabilities = best_model_lgbm.predict_proba(final_df)[:,1]\n",
    "\n",
    "# Create true and false positive rates\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(df[Y], target_probabilities)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A-OK_ot5Jkry",
   "metadata": {
    "id": "A-OK_ot5Jkry"
   },
   "source": [
    "## Explanation of models used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff0d11",
   "metadata": {
    "id": "a9ff0d11"
   },
   "source": [
    "After the preprocessing was done, many models were attempted, but only the best models where kept (accuracy > 95%), as they were all near the final score of 97.170% (this is not the final accuracy, this will be explained later). It seems like that tree related models, especially boosted models gave good results when we use this data set. For example, sector vector machines gave an accuracy of around 80% while training; k-nearest neighbors gave decent results while training (93-94%). However the accuracy on Kaggle went under the 90% threshold; the other models attempted were the decision tree with accuracies around 94% (not many tests were done with these). Logistic regression was also experimented with but returned disappointing results with accuracies below 90%. <br>\n",
    "\n",
    "To perform the hyperparameterization in these models we opted to used gridsearch but, since there were too many parameters to optimize, we opted for the randomizedsearch. Since we used random search, which does not return the best method at the start, we ran this hyperparmeterization method a couple of times until we obtained our best model.<br>\n",
    "\n",
    "In this part of the work, we used ROC curves and confusion matrixes to understand what were the problems with the models. In most cases it was overfitting, many attempts were done to mitigate this problem (limiting depth, l2_reg, and other parameters that are incorporated in the catboost), but none were successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17468c2",
   "metadata": {
    "id": "d17468c2"
   },
   "source": [
    "# AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efff35e",
   "metadata": {
    "id": "1efff35e"
   },
   "source": [
    "Another attempt was to use AutoML to perform hyperparameterization but we could not get better results than we did with a randomized grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374af8eb",
   "metadata": {
    "id": "374af8eb",
    "outputId": "da095a9a-b362-49b0-c77b-d98ce15b8f1d"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # Definition of space search\n",
    "    loss_function = trial.suggest_categorical('loss_function', ['Logloss', 'CrossEntropy'])\n",
    "    iterations = trial.suggest_int('iterations', 500, 3000)\n",
    "    depth = trial.suggest_int('max_depth', 2, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate',0.1,0.3,step=0.02)\n",
    "    l2_leaf_reg = trial.suggest_float('l2_leaf_reg',0,0.3,step=0.02)\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 20, 40)\n",
    "    best_model_min_trees = trial.suggest_int('min_data_in_leaf', 2, 10)\n",
    "\n",
    "\n",
    "    \n",
    "    # Classifier definition\n",
    "    model = CatBoostClassifier(loss_function=loss_function,\n",
    "                                iterations=iterations,\n",
    "                                depth=depth,\n",
    "                                learning_rate=learning_rate,\n",
    "                                l2_leaf_reg=l2_leaf_reg,\n",
    "                                min_data_in_leaf=min_data_in_leaf,\n",
    "                                best_model_min_trees=best_model_min_trees,\n",
    "                                logging_level = 'Silent')\n",
    "\n",
    "    score=model_selection.cross_val_score(model, final_df, target_df, n_jobs=-1, cv=10, error_score='raise', scoring='f1_macro' )\n",
    "    accuracy=score.mean()\n",
    "    return accuracy \n",
    "\n",
    "study=optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55f71f",
   "metadata": {
    "id": "3f55f71f"
   },
   "outputs": [],
   "source": [
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae6c81",
   "metadata": {
    "id": "cfae6c81",
    "outputId": "aaedd563-5224-4bab-e2b7-43cff3cf771d"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # Definition of space search\n",
    "    randomforest = RandomForestClassifier(n_jobs=-1)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss'])\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 500)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 500)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 500)\n",
    "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2']) #The number of features to consider when looking for the best split:\n",
    "    max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 2, 500)\n",
    "    n_estimators = trial.suggest_int('max_depth', 200, 3000)\n",
    "\n",
    "    # Classifier definition\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, max_features=max_features, max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "    score=model_selection.cross_val_score(model, final_df, df[Y], n_jobs=-1, cv=5, scoring='f1')\n",
    "    accuracy=score.mean()\n",
    "    return accuracy \n",
    "\n",
    "study=optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e1a7b",
   "metadata": {
    "id": "204e1a7b",
    "outputId": "26ae1cfe-d5e2-4dca-d0ad-77ca75008250"
   },
   "outputs": [],
   "source": [
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa21e147",
   "metadata": {
    "id": "fa21e147",
    "outputId": "cdca8741-a0ed-42d1-ded2-2efeb4a05341"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # Definition of space search\n",
    "    learning_rate = trial.suggest_float('learning_rate',0.1,1.0,step=0.05)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 200, 800)\n",
    "    num_leaves = trial.suggest_int('num_leaves', 2, 100)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 100)\n",
    "    boosting_type = trial.suggest_categorical('boosting_type', ['gbdt', 'dart','goss'])\n",
    "    objective = trial.suggest_categorical('objective', ['binary'])\n",
    "    subsample=trial.suggest_float('subsample',0.1,1.0,step=0.05)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 100)\n",
    "    reg_alpha = trial.suggest_float('reg_alpha',0.1,1.5,step=0.05)\n",
    "    reg_lambda = trial.suggest_float('reg_lambda',0.1,1.5,step=0.05)\n",
    "\n",
    "    # Classifier definition\n",
    "    model = LGBMClassifier(n_estimators=n_estimators, learning_rate=learning_rate, num_leaves=num_leaves, \n",
    "                           min_samples_leaf=min_samples_leaf, boosting_type=boosting_type, \n",
    "                           objective=objective, subsample=subsample, max_depth=max_depth,\n",
    "                           reg_alpha=reg_alpha, reg_lambda=reg_lambda)\n",
    "\n",
    "    score=model_selection.cross_val_score(model, final_df, df[Y], n_jobs=-1, cv=5,error_score='raise', scoring='f1')\n",
    "    accuracy=score.mean()\n",
    "    return accuracy \n",
    "\n",
    "study=optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f28fa7f",
   "metadata": {
    "id": "5f28fa7f",
    "outputId": "23d22af4-ef54-46a6-a409-05a5c26e7430"
   },
   "outputs": [],
   "source": [
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c270d199",
   "metadata": {
    "id": "c270d199",
    "outputId": "2e68f895-11d7-4a1e-cc72-c08d1e2ae77b"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # Definition of space search\n",
    "    randomforest = XGBClassifier()\n",
    "    learning_rate = trial.suggest_float('learning_rate',0.1,1.0,step=0.05)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 200, 3000)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 500)\n",
    "    min_child_weight = trial.suggest_float('min_child_weight',0.1,1.0,step=0.05)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree',0.1,1.0,step=0.05)\n",
    "\n",
    "    # Classifier definition\n",
    "    model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, \n",
    "                           min_child_weight=min_child_weight, colsample_bytree=colsample_bytree)\n",
    "\n",
    "    score=model_selection.cross_val_score(model, final_df, df[Y], n_jobs=-1, cv=5,error_score='raise', scoring='f1')\n",
    "    accuracy=score.mean()\n",
    "    return accuracy \n",
    "\n",
    "study=optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904501af",
   "metadata": {
    "id": "904501af",
    "outputId": "12fbc9d1-359e-4970-c4d4-5d5839ecc4eb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # Definition of space search\n",
    "    randomforest = GradientBoostingClassifier()\n",
    "    learning_rate = trial.suggest_float('learning_rate',0.1,1.0,step=0.05)\n",
    "    loss = trial.suggest_categorical('loss', ['log_loss', 'deviance', 'exponential'])\n",
    "    min_samples_split=trial.suggest_float('min_samples_split',0.05,1.0,step=0.05)\n",
    "    min_samples_leaf=trial.suggest_float('min_samples_leaf',0.05,1.0,step=0.05)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 50)\n",
    "    max_features = trial.suggest_categorical('max_features',['auto',\"log2\",\"sqrt\"])\n",
    "    criterion = trial.suggest_categorical('criterion',[\"friedman_mse\",  \"squared_error\", 'mse'])\n",
    "    subsample=trial.suggest_float('subsample',0.05,1.0,step=0.05)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 200, 3000)\n",
    "\n",
    "    # Classifier definition\n",
    "    model = GradientBoostingClassifier(learning_rate=learning_rate, loss=loss, min_samples_split=min_samples_split, \n",
    "                           min_samples_leaf=min_samples_leaf, max_depth=max_depth, max_features=max_features,\n",
    "                           criterion=criterion, subsample=subsample, n_estimators=n_estimators)\n",
    "\n",
    "    score=model_selection.cross_val_score(model, final_df, target_df, n_jobs=-1, cv=5,error_score='raise',scoring='f1_macro')\n",
    "    accuracy=score.mean()\n",
    "    return accuracy \n",
    "\n",
    "study=optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KleA69WOP0Og",
   "metadata": {
    "id": "KleA69WOP0Og"
   },
   "source": [
    "# Extra attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "# Generate the training curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(model, final_df, target_df, cv=5, scoring='f1', n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 10))\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis=1), 'o-', color='r', label='Training score')\n",
    "plt.plot(train_sizes, np.mean(test_scores, axis=1), 'o-', color='g', label='Cross-validation score')\n",
    "plt.xlabel('Training size')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2133cf",
   "metadata": {
    "id": "fa2133cf"
   },
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016bf83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b016bf83",
    "outputId": "e220cfb2-92a7-411e-b9c1-e51ca4d1d385"
   },
   "outputs": [],
   "source": [
    "# importing utility modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "# importing machine learning models for prediction\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "# importing voting classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    " \n",
    "# Splitting between train data into training and validation dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df, df[Y], test_size=0.3, random_state=0)\n",
    "\n",
    "# initializing all the model objects with default parameters\n",
    "model_1 = GradientBoostingClassifier()\n",
    "model_2 = XGBClassifier()\n",
    "model_3 = GaussianNB()\n",
    " \n",
    "# Making the final model using voting classifier\n",
    "best_model = VotingClassifier(\n",
    "    estimators=[('cat', model_1), ('xgb', model_2), ('lgbm', model_3)], voting='soft')\n",
    " \n",
    "# training all the model on the train dataset\n",
    "best_model.fit(X_train, y_train)\n",
    " \n",
    "# predicting the output on the test dataset\n",
    "pred_final = best_model.predict(X_test)\n",
    " \n",
    "# printing log loss between actual and predicted value\n",
    "print(log_loss(y_test, pred_final))\n",
    "print(f1_score(y_test, pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6g500RBM85HH",
   "metadata": {
    "id": "6g500RBM85HH"
   },
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2P8HT4qY9Eep",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2P8HT4qY9Eep",
    "outputId": "1470ef4c-f3f0-4a75-ed0d-9833ee132268"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators= 1600, min_samples_split= 15, min_samples_leaf= 15, max_leaf_nodes= 100, max_features= 'sqrt', max_depth= 100, criterion= 'entropy', bootstrap= False)),\n",
    "    ('xgb', XGBClassifier(reg_lambda= 0, reg_alpha= 0.1, n_estimators= 1000, min_child_weight= 1, max_depth= 6, learning_rate= 0.4, gamma= 0, colsample_bytree= 0.6))]\n",
    "\n",
    "\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=CatBoostClassifier(nan_mode='Max',random_strength= 10, min_data_in_leaf= 30, loss_function= 'CrossEntropy', learning_rate= 0.2 , l2_leaf_reg= 0.1, iterations= 1000, depth= 5, border_count= 200, best_model_min_trees= 3))\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     final_df, df[Y], stratify=df[Y], random_state=42 )\n",
    "clf.fit(X_train, y_train).score(X_test, y_test,scoring='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gZWxb-Th7Qz-",
   "metadata": {
    "id": "gZWxb-Th7Qz-"
   },
   "source": [
    "## Bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "luFlXGIl7H4E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "luFlXGIl7H4E",
    "outputId": "318d6ad3-9e99-49a9-8a0b-5b2338aebd12"
   },
   "outputs": [],
   "source": [
    "#16\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df, df[Y], test_size = 0.3)\n",
    "\n",
    "estimator_range = range(10,20)\n",
    "\n",
    "models = []\n",
    "scores = []\n",
    "\n",
    "for n_estimators in estimator_range:\n",
    "\n",
    "    # Create bagging classifier\n",
    "    clf = BaggingClassifier(base_estimator=CatBoostClassifier(logging_level='Silent',nan_mode='Max',random_strength= 10, min_data_in_leaf= 30, loss_function= 'CrossEntropy', learning_rate= 0.2 , l2_leaf_reg= 0.1, iterations= 1000, depth= 5, border_count= 200, best_model_min_trees= 3), n_estimators = n_estimators)\n",
    "\n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Append the model and score to their respective list\n",
    "    models.append(clf)\n",
    "    scores.append(cross_val_score(clf, final_df, df[Y], scoring='f1').mean())\n",
    "\n",
    "# Generate the plot of scores against number of estimators\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(estimator_range, scores)\n",
    "\n",
    "# Adjust labels and font (to make visable)\n",
    "plt.xlabel(\"n_estimators\", fontsize = 18)\n",
    "plt.ylabel(\"score\", fontsize = 18)\n",
    "plt.tick_params(labelsize = 16)\n",
    "\n",
    "# Visualize plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TxxSJYOLBOka",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TxxSJYOLBOka",
    "outputId": "69153068-05f2-43a7-814e-3ee36e8587fe"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Create bagging classifier\n",
    "clf = BaggingClassifier(base_estimator=CatBoostClassifier(logging_level='Silent',nan_mode='Max',random_strength= 10, min_data_in_leaf= 30, loss_function= 'CrossEntropy', learning_rate= 0.2 , l2_leaf_reg= 0.1, iterations= 1000, depth= 5, border_count= 200, best_model_min_trees= 3), n_estimators = 11)\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(final_df, df[Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7c4c0c",
   "metadata": {
    "id": "6b7c4c0c"
   },
   "source": [
    "## Extra models explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6pbZegtxLHTq",
   "metadata": {
    "id": "6pbZegtxLHTq"
   },
   "source": [
    "To mitigate overfitting, bagging, voting, and stacking were performed, but every attempt only worsened our final accuracy, even in training, so none were used in the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6767279c",
   "metadata": {
    "id": "6767279c"
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f601cc",
   "metadata": {
    "id": "90f601cc"
   },
   "source": [
    "In this part of the notebook the predictions were done. Here, we also added our best model, which did not need much manual preprocessing, needing only feature selection.\n",
    "\n",
    "It seems like catboost does not require missing value substition because this model has an internal mechanism to do so, which substitutes the missing values by a value lower or higher than any other value. In this data set, there was no distinction in accuracy between both methods.\n",
    "\n",
    "However, for simplicity's sake, as we said previously, in the next steps, we used the function df_value which substituted the missing values by 9999 and had the same accuracy.\n",
    "\n",
    "Another thing that we discovered was that by changing the threshold of the predictions, we could improved the accuracy of the model to 0.97252 (threshold=0.7 or 0.8). We decided to do this because when we did the explainability, we noticed that a lot of predictions on the target set had high prediction probability (near 100%), which were normally the correctly predicted ones, on the contrary, the incorrect ones, had more often lower probabilities, so we decided to experiment with the probability threshold to improve accuracy. Of course, since our model was overffited, the choice of the threshold was done by trial and error. We discovered some of the predictions that were wrong, by applying brute force, which is explained in the explainability section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd730358",
   "metadata": {
    "id": "dd730358"
   },
   "outputs": [],
   "source": [
    "#missing values target\n",
    "target=pd.read_csv('task.csv')\n",
    "ids=target['i']\n",
    "target=df_value(target.loc[:,'d1':'x9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZASM68tyExdd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZASM68tyExdd",
    "outputId": "458ea5e6-45bc-4d6a-a648-b436e1838f15"
   },
   "outputs": [],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f267a61",
   "metadata": {
    "id": "2f267a61"
   },
   "outputs": [],
   "source": [
    "#best model\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "best_model=GradientBoostingClassifier(learning_rate= 0.1,\n",
    " loss= 'exponential',\n",
    " min_samples_split= 0.6500000000000001,\n",
    " min_samples_leaf= 0.05,\n",
    " max_depth= 34,\n",
    " max_features= 'sqrt',\n",
    " criterion= 'mse',\n",
    " subsample= 1.0,\n",
    " n_estimators= 291)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lLUIOonRSbac",
   "metadata": {
    "id": "lLUIOonRSbac"
   },
   "outputs": [],
   "source": [
    "#y_pred = (best_model.predict_proba(target)[:,1] >= 0.3).astype(int) # set threshold as 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZA_vkPW2h6yw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZA_vkPW2h6yw",
    "outputId": "58fa3b51-d888-44ea-99fa-90b2e752d82b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(best_model, final_df, df[Y]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce758d58",
   "metadata": {
    "id": "ce758d58"
   },
   "outputs": [],
   "source": [
    "# create data frame with predictions\n",
    "#substitute model\n",
    "final=pd.concat([ids, pd.DataFrame(best_model.predict(target[X].loc[:,final_df.columns]))], axis=1).rename(columns={0:'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CSEx82p-T0VC",
   "metadata": {
    "id": "CSEx82p-T0VC"
   },
   "outputs": [],
   "source": [
    "# prediction with threshold\n",
    "final=pd.concat([ids, pd.DataFrame((best_model.predict_proba(target)[:,1] >= 0.7).astype(int))], axis=1).rename(columns={0:'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42673c",
   "metadata": {
    "id": "dc42673c"
   },
   "outputs": [],
   "source": [
    "#create csv\n",
    "final.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c47712",
   "metadata": {
    "id": "32c47712"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f101539b",
   "metadata": {
    "id": "f101539b"
   },
   "source": [
    "To analyse our final model, we created this section so we did not need to search for it in the model section, to see what was the problem with our model. It seems that its problem is, again, overfiting, as it predicts every observation correctly in this training set. Some attempts to decrease overfitting were tried with catboost's internal mechanisms (l2_reg, od_pval and od_wait), but it was not successful because Kaggle's and the training accuracy decreased, which suggests that the two data sets are very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4dbb51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "8a4dbb51",
    "outputId": "f9475175-30d0-41c5-f481-d1559bc7dff5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[X], df[Y], test_size=0.33, random_state=1)\n",
    "\n",
    "# Get predicted probabilities\n",
    "target_probabilities = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Create true and false positive rates\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, target_probabilities)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff9378",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "93ff9378",
    "outputId": "3ac5ce3d-d7cd-471a-9289-26df657405fa"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "best_model=CatBoostClassifier(logging_level='Silent', nan_mode='Max',random_strength= 10, min_data_in_leaf= 30, loss_function= 'CrossEntropy', learning_rate= 0.2 , l2_leaf_reg= 0.1, iterations= 1000, depth= 5, border_count= 200, best_model_min_trees= 3).fit(final_df, df_no_na[Y])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[X], df[Y], test_size=0.33)\n",
    "\n",
    "print(best_model.score(X_test, y_test, scoring='f1'))\n",
    "\n",
    "matrix = confusion_matrix(y_test, best_model.predict(X_test))\n",
    "dataframe = pd.DataFrame(matrix, index=[0,1], columns=[0,1])\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "print(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f8a9a",
   "metadata": {
    "id": "2b1f8a9a",
    "outputId": "1598a97c-cd3f-48e4-e93f-24b385a36b8c"
   },
   "outputs": [],
   "source": [
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, best_model.predict(X_test), target_names=['0','1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76405927",
   "metadata": {
    "id": "76405927"
   },
   "source": [
    "# Validation Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3635f6af",
   "metadata": {
    "id": "3635f6af"
   },
   "source": [
    "To reduce overfitting, which we mentioned in the last section, we tried a validation curve, so we could know in which way to optimize the l2_reg, but we ended up seeing that the alteration of a this parameter would not have a positive impact on the dataset prediction, as the accuracy changed very little and it only decreased. So this was of no help in the final prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e706ab6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "6e706ab6",
    "outputId": "3b9044f5-f1e5-4a99-9d50-80d43d9fbf92"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# Create range of values for parameter\n",
    "param_range = np.arange(1, 250, 2)\n",
    "\n",
    "# Hyperparameter to examine\n",
    "param_name=\"l2_leaf_reg\"\n",
    "\n",
    "# Range of hyperparameter's values\n",
    "param_range = np.arange(0.1, 10, 0.1)\n",
    "\n",
    "# Calculate accuracy on training and test set using range of parameter values\n",
    "train_scores, test_scores = validation_curve(best_model, final_df, df[Y], param_name=param_name, param_range=param_range, cv=5, scoring=\"f1\", n_jobs=-1)\n",
    "\n",
    "# Calculate mean and standard deviation for training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Calculate mean and standard deviation for test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot mean accuracy scores for training and test sets\n",
    "plt.plot(param_range, train_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_mean, label=\"Cross-validation score\", color=\"dimgrey\")\n",
    "\n",
    "# Plot accurancy bands for training and test sets\n",
    "plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_mean - test_std, test_mean + test_std, color=\"gainsboro\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Validation Curve With Random Forest\")\n",
    "plt.xlabel(\"Number Of Trees\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb74fb",
   "metadata": {
    "id": "bccb74fb"
   },
   "source": [
    "# Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8Ob-UF-5NYAi",
   "metadata": {
    "id": "8Ob-UF-5NYAi"
   },
   "source": [
    "Before starting this part, as suggested in previous ones, we would like to say that the explainability models here were applied to our best model only,ending up helping in the feature selection. We removed x4 from the data set because it had really low explainability, as said. This may mean that it could help in the predictions of this data set but may not be as important in the prediction of other data sets or even skew the predictions. So for the sake of getting a better accuracy we tried to remove it, which made the prediction slightly better. We attempted to do this with d2 and d11, but it only worsen our results.\n",
    "\n",
    "Another thing that should be said is that our best prediction was accomplished by trial and error. We removed the variables with the lowest explainability in the data set (x4, d11, d2) and then saw which were the predictions that were not compatible between model predictions using Excel. Afterwards we proceeded to substitute these predictions, one by one, by their opposite in our best prediction set, so we could know some of the predictions that were incorrectly and correctly predicted by our model and also increase our accuracy. Even though our highest prediction with a model is 0.97252, our best accuracy on Kaggle is 0.97660 because of this.\n",
    "\n",
    "We wanted to know which predictions were incorrectly classified, so we could use them in explainability models to see which variables were skewing them, and try to address the problem. However, since we are not experts in explainability, it was not possible to improve our results, because even though, one variables turns a prediction incorrect, it helps many other. \n",
    "\n",
    "So, in conclusion, the best model only needed missing value substitution by an arbitrarly big number and feature selection with recursive feature elemination. The further model improvements (thresholdin and further feature selection) were done with the help of the explanation models, primarly the permutation importance table and the lime model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OrDySD5VvFys",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrDySD5VvFys",
    "outputId": "caf08f13-171e-4712-8224-7bc77f8aca8d"
   },
   "outputs": [],
   "source": [
    "pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vvSnO7AGTvpp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vvSnO7AGTvpp",
    "outputId": "6ed4c06f-92c7-4b85-cadd-80e742ba2b48"
   },
   "outputs": [],
   "source": [
    "import lime \n",
    "from lime import lime_tabular\n",
    "\n",
    "lime_explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array(final_df),\n",
    "    feature_names=final_df.columns,\n",
    "    class_names=['notdisc', 'disc'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "for i in range(0,20):\n",
    "    lime_exp = lime_explainer.explain_instance(\n",
    "        data_row=final_df.iloc[i],\n",
    "        predict_fn=best_model.predict_proba\n",
    "    )\n",
    "    lime_exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YnEuk1mqFvN1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YnEuk1mqFvN1",
    "outputId": "572093d2-03a4-4be6-cf93-692889ac55d3"
   },
   "outputs": [],
   "source": [
    "# wrongly and correctly predicted observations in target csv\n",
    "import lime \n",
    "from lime import lime_tabular\n",
    "\n",
    "target=pd.read_csv('task.csv')\n",
    "target=df_value(target)\n",
    "final_target=target[['d2','d11']+numbers[:3]+numbers[4:]]\n",
    "i_target=target[['i','d2','d11']+numbers[:3]+numbers[4:]]\n",
    "\n",
    "correct_preds=[23, 221, 429]\n",
    "wrong_preds=[1085, 1685, 1915,2187, 2685, 2700, 3456, 5056] #1685 was classified as 1, 1085 as 1, 1915 as 0\n",
    "\n",
    "lime_explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array(final_target),\n",
    "    feature_names=final_target.columns,\n",
    "    class_names=['notdisc', 'disc'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "for i in correct_preds+wrong_preds:\n",
    "    row=i_target.loc[target.loc[:,'i']==i,['d2','d11']+numbers[:3]+numbers[4:]]\n",
    "    row=row.squeeze() \n",
    "    if i in correct_preds:\n",
    "        print('Correctly classified')\n",
    "    else:\n",
    "        print('Wrongly classified')\n",
    "    lime_exp = lime_explainer.explain_instance(\n",
    "        data_row=row,\n",
    "        predict_fn=best_model.predict_proba\n",
    "    )\n",
    "    lime_exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xP7JQKMgJD8W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xP7JQKMgJD8W",
    "outputId": "1e82dd11-b341-4be7-e253-bff5416a8de0"
   },
   "outputs": [],
   "source": [
    "pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XMssFVL0UGeA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "XMssFVL0UGeA",
    "outputId": "1de61b55-a098-4849-983f-68cc08d2b13f"
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "shap_explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = shap_explainer.shap_values(final_df)\n",
    "\n",
    "shap.summary_plot(shap_values, final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402e3ece",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "402e3ece",
    "outputId": "1f8b109e-ebf0-4d90-b527-188da825798d"
   },
   "outputs": [],
   "source": [
    "# visualize the first prediction's explanation\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values[0,:], final_df.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eQTCXnXpYItf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "eQTCXnXpYItf",
    "outputId": "f223d821-04b0-4bc1-b541-bfe8fe7ba01d"
   },
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values[1,:], final_df.iloc[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zODPH5dBYN7Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "zODPH5dBYN7Y",
    "outputId": "2277991d-1abd-4ac8-a27a-c245bd17658c"
   },
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values[2,:], final_df.iloc[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6qsGj1lSYwDN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "6qsGj1lSYwDN",
    "outputId": "edd4f3de-864d-499b-ba9d-a251e9fd650b"
   },
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values[3,:], final_df.iloc[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PvIyirygY8uy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "PvIyirygY8uy",
    "outputId": "ba463a52-d5da-4c51-8063-743f98936bbd"
   },
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values[7,:], final_df.iloc[7,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fenXmk2cY_yF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "fenXmk2cY_yF",
    "outputId": "f3b4bbf1-71eb-4b48-b5a8-c28b644cc78a"
   },
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values[17,:], final_df.iloc[17,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mgQgY1gUQxM0",
   "metadata": {
    "id": "mgQgY1gUQxM0"
   },
   "source": [
    "Wrongly classified and correctly classified with shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_bc7dei1Q8lj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "_bc7dei1Q8lj",
    "outputId": "c4e43999-5531-49f0-c48c-e84f92933de0"
   },
   "outputs": [],
   "source": [
    "target=pd.read_csv('task.csv')\n",
    "target=df_value(target)\n",
    "final_target=target[['d2','d11']+numbers[:3]+numbers[4:]]\n",
    "i_target=target[['i','d2','d11']+numbers[:3]+numbers[4:]]\n",
    "\n",
    "shap_values_target = shap_explainer.shap_values(final_target)\n",
    "row=i_target.loc[target.loc[:,'i']==23,['d2','d11']+numbers[:3]+numbers[4:]]\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values_target[target.loc[:,'i']==23,:], row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kA_WBJBqRvSL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "kA_WBJBqRvSL",
    "outputId": "856d298c-b027-47de-f721-a4e04b07422d"
   },
   "outputs": [],
   "source": [
    "row=i_target.loc[target.loc[:,'i']==221,['d2','d11']+numbers[:3]+numbers[4:]]\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values_target[target.loc[:,'i']==221,:], row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kc8Itfd4Rvj2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "kc8Itfd4Rvj2",
    "outputId": "29a4e622-e76d-43cb-c58d-096951486953"
   },
   "outputs": [],
   "source": [
    "row=i_target.loc[target.loc[:,'i']==429,['d2','d11']+numbers[:3]+numbers[4:]]\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values_target[target.loc[:,'i']==429,:], row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6Y5NFoEAR1CW",
   "metadata": {
    "id": "6Y5NFoEAR1CW"
   },
   "source": [
    "wrongly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XElj6ZkXRvso",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "XElj6ZkXRvso",
    "outputId": "f1396c78-c230-4809-b6c7-8b83d7bd86de"
   },
   "outputs": [],
   "source": [
    "row=i_target.loc[target.loc[:,'i']==1085,['d2','d11']+numbers[:3]+numbers[4:]]\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values_target[target.loc[:,'i']==1085,:], row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfOG3fZwRv1G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "bfOG3fZwRv1G",
    "outputId": "1e02c67a-b37f-497a-bb79-a449f2205cde"
   },
   "outputs": [],
   "source": [
    "row=i_target.loc[target.loc[:,'i']==1685,['d2','d11']+numbers[:3]+numbers[4:]]\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values_target[target.loc[:,'i']==1685,:], row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ttcea5ydRwJz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "ttcea5ydRwJz",
    "outputId": "8fc2122d-b179-4112-bcdf-012e9c455f63"
   },
   "outputs": [],
   "source": [
    "target=pd.read_csv('task.csv')\n",
    "target=df_value(target)\n",
    "final_target=target[['d2','d11']+numbers[:3]+numbers[4:]]\n",
    "i_target=target[['i','d2','d11']+numbers[:3]+numbers[4:]]\n",
    "\n",
    "row=i_target.loc[target.loc[:,'i']==1915,['d2','d11']+numbers[:3]+numbers[4:]]\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values_target[target.loc[:,'i']==1915,:], row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZqoX4yd_EeRs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "ZqoX4yd_EeRs",
    "outputId": "60fd9bd8-e56c-49f9-d32e-945d2e0dc27a"
   },
   "outputs": [],
   "source": [
    "row=i_target.loc[target.loc[:,'i']==2187,['d2','d11']+numbers[:3]+numbers[4:]]\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values_target[target.loc[:,'i']==2187,:], row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hE-5s5wpEeh1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "hE-5s5wpEeh1",
    "outputId": "f3a09908-7312-4c73-d509-2c739e36e85d"
   },
   "outputs": [],
   "source": [
    "row=i_target.loc[target.loc[:,'i']==2685,['d2','d11']+numbers[:3]+numbers[4:]]\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values_target[target.loc[:,'i']==2685,:], row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DY4epGg5EevR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "DY4epGg5EevR",
    "outputId": "c0736507-e8dc-4047-bff1-02bf80be3e99"
   },
   "outputs": [],
   "source": [
    "row=i_target.loc[target.loc[:,'i']==2700,['d2','d11']+numbers[:3]+numbers[4:]]\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values_target[target.loc[:,'i']==2700,:], row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yXkn4u-hEe7U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "yXkn4u-hEe7U",
    "outputId": "d3c9485b-23a2-416d-fb14-4ab981d160e6"
   },
   "outputs": [],
   "source": [
    "row=i_target.loc[target.loc[:,'i']==3456,['d2','d11']+numbers[:3]+numbers[4:]]\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values_target[target.loc[:,'i']==3456,:], row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CjiFTislEfIX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "CjiFTislEfIX",
    "outputId": "366cab8b-3b8e-42c6-c57c-e11c5e6e5076"
   },
   "outputs": [],
   "source": [
    "row=i_target.loc[target.loc[:,'i']==5056,['d2','d11']+numbers[:3]+numbers[4:]]\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values_target[target.loc[:,'i']==5056,:], row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3926f175",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3926f175",
    "outputId": "e1b86c92-1cce-47d0-8488-aae8fc510460"
   },
   "outputs": [],
   "source": [
    "# create a SHAP dependence plot to show the effect of a single feature across the whole dataset\n",
    "shap.initjs()\n",
    "for i in final_df.columns:    \n",
    "    shap.dependence_plot(i, shap_values, final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gY0S2mrzbAyf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "gY0S2mrzbAyf",
    "outputId": "588afe67-d5f6-468b-b33d-8ee148142bd5"
   },
   "outputs": [],
   "source": [
    "# visualize the training set predictions\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values, final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0696J6aXQJD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "a0696J6aXQJD",
    "outputId": "d0007f67-74e7-457a-f208-01613c25711b"
   },
   "outputs": [],
   "source": [
    "# visualize the target set predictions\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values_target, final_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "btFg_WyQLNY3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btFg_WyQLNY3",
    "outputId": "ca486ff8-1cae-4e1a-b212-8ce3c984e61f"
   },
   "outputs": [],
   "source": [
    "pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8775534a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "8775534a",
    "outputId": "b7518005-8863-4ee6-d60c-dce8388d51aa"
   },
   "outputs": [],
   "source": [
    "#permutation importance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(best_model, random_state=1).fit(final_df, df[Y])\n",
    "eli5.show_weights(perm, feature_names = final_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WuWVlweTKHmR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "id": "WuWVlweTKHmR",
    "outputId": "d6853c9a-3856-444a-933d-06536d22364e"
   },
   "outputs": [],
   "source": [
    "pip install pdpbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fe2137",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "40fe2137",
    "outputId": "8404f991-966b-46c1-dbfd-0cd45ea3fc4c"
   },
   "outputs": [],
   "source": [
    "# Partial Plots\n",
    "#perguntar pelo que substituir o x9\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "for i in final_df.columns: \n",
    "    feature_to_plot = i\n",
    "    pdp_dist = pdp.pdp_isolate(model=best_model, dataset=final_df, model_features=final_df.columns, feature=feature_to_plot)\n",
    "\n",
    "    pdp.pdp_plot(pdp_dist, feature_to_plot)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "53ed1c6b",
    "e8119bbb",
    "53b8cfb0",
    "c1a70712",
    "39beec75",
    "ejp5NQ599tNf",
    "afb295e3",
    "626d5e46",
    "287fab33",
    "d99a4b61",
    "4d04f977",
    "1458bb5e",
    "1fc5983f",
    "21af0416",
    "81aa9d19",
    "13a6acc5",
    "A-OK_ot5Jkry",
    "d17468c2",
    "fa2133cf",
    "6g500RBM85HH",
    "gZWxb-Th7Qz-",
    "6b7c4c0c",
    "6767279c",
    "32c47712",
    "76405927",
    "bccb74fb"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
